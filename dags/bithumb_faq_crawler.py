"""
ë¹—ì¸ FAQ í¬ë¡¤ë§ Airflow DAG
ë§¤ì¼ ìžë™ìœ¼ë¡œ ë¹—ì¸ ê³ ê°ì§€ì› ì„¼í„° FAQë¥¼ í¬ë¡¤ë§í•˜ì—¬ MongoDB Atlasì— ì €ìž¥í•©ë‹ˆë‹¤.
app/scripts/data/crawl_bithumb_playwright.pyë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.utils.task_group import TaskGroup
import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
# Airflow ì»¨í…Œì´ë„ˆì—ì„œëŠ” /opt/airflow/projectë¡œ ë§ˆìš´íŠ¸ë¨
project_root = Path('/opt/airflow/project')
if not project_root.exists():
    # ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œëŠ” ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©
    project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv

# 1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ í™•ì¸
project_env = project_root / '.env'
# 2. airflow í´ë”ì˜ .env íŒŒì¼ í™•ì¸
airflow_dir = Path(__file__).parent.parent
airflow_env = airflow_dir / '.env'

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ .env ë¨¼ì € ë¡œë“œ
if project_env.exists():
    load_dotenv(project_env)

# airflow/.env íŒŒì¼ì´ ìžˆìœ¼ë©´ ìš°ì„ ìˆœìœ„ë¡œ ë¡œë“œ (override=True)
if airflow_env.exists():
    load_dotenv(airflow_env, override=True)

default_args = {
    'owner': 'bithumb-crawler',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'start_date': datetime(2024, 1, 1),
}

dag = DAG(
    'bithumb_faq_crawler',
    default_args=default_args,
    description='ë¹—ì¸ FAQ í¬ë¡¤ë§ ë° MongoDB Atlas ì €ìž¥ (Playwright ì‚¬ìš©)',
    schedule_interval='0 2 * * *',  # ë§¤ì¼ ì˜¤ì „ 2ì‹œ ì‹¤í–‰
    catchup=False,
    tags=['bithumb', 'crawler', 'faq', 'mongodb', 'playwright'],
    max_active_runs=1,  # ë™ì‹œ ì‹¤í–‰ ë°©ì§€
)


def check_playwright_installation(**context):
    """Playwright ì„¤ì¹˜ í™•ì¸"""
    import logging
    
    logger = logging.getLogger(__name__)
    logger.info("Playwright ì„¤ì¹˜ í™•ì¸ ì‹œìž‘...")
    
    try:
        from playwright.async_api import async_playwright
        logger.info("âœ… Playwright Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸ë¨")
        return True
    except ImportError:
        error_msg = "Playwrightê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. requirements.txtì— playwrightê°€ í¬í•¨ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
        logger.error(f"âŒ {error_msg}")
        raise ImportError(error_msg)


def check_mongodb_connection(**context):
    """MongoDB ì—°ê²° ìƒíƒœ í™•ì¸ (Airflow ì „ìš© ëª¨ë“ˆ ì‚¬ìš©)"""
    import asyncio
    import logging
    
    logger = logging.getLogger(__name__)
    logger.info("MongoDB ì—°ê²° í™•ì¸ ì‹œìž‘...")
    
    # Airflow ì „ìš© ëª¨ë“ˆ ì‚¬ìš© (appê³¼ ì™„ì „ížˆ ë¶„ë¦¬)
    from airflow.scripts.mongodb_store import AirflowVectorStore
    
    async def _check():
        vector_store = AirflowVectorStore()
        connected = await vector_store.connect()
        if connected:
            logger.info("âœ… MongoDB ì—°ê²° ì„±ê³µ")
            await vector_store.disconnect()
            return True
        else:
            logger.error("âŒ MongoDB ì—°ê²° ì‹¤íŒ¨")
            return False
    
    try:
        result = asyncio.run(_check())
        if not result:
            raise Exception("MongoDB ì—°ê²° ì‹¤íŒ¨ - í™˜ê²½ ë³€ìˆ˜(MONGODB_URI, MONGODB_DATABASE)ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        return result
    except Exception as e:
        logger.error(f"MongoDB ì—°ê²° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        raise


def run_crawl_bithumb_faq(**context):
    """ë¹—ì¸ FAQ í¬ë¡¤ë§ ì‹¤í–‰ (Airflow ì „ìš© ëª¨ë“ˆ ì‚¬ìš©)"""
    import asyncio
    import logging
    
    logger = logging.getLogger(__name__)
    logger.info("=" * 60)
    logger.info("ë¹—ì¸ FAQ í¬ë¡¤ë§ ì‹œìž‘ (Playwright ì‚¬ìš©)")
    logger.info("=" * 60)
    
    # Airflow ì „ìš© í¬ë¡¤ë§ ëª¨ë“ˆ ì‚¬ìš© (appê³¼ ì™„ì „ížˆ ë¶„ë¦¬)
    from airflow.scripts.bithumb_crawler import crawl_bithumb_faq
    
    try:
        # Playwright ì‚¬ìš© í¬ë¡¤ë§ ì‹¤í–‰ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ)
        # limit=Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ëª¨ë“  ì•„í‹°í´ í¬ë¡¤ë§
        asyncio.run(crawl_bithumb_faq(limit=None, headless=True))
        logger.info("âœ… ë¹—ì¸ FAQ í¬ë¡¤ë§ ì™„ë£Œ")
        
        # Airflow XComì— ì„±ê³µ ì •ë³´ ì €ìž¥
        context['ti'].xcom_push(key='crawl_status', value='success')
        context['ti'].xcom_push(key='crawl_method', value='playwright')
        return 'success'
        
    except Exception as e:
        logger.error(f"âŒ ë¹—ì¸ FAQ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        logger.exception("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        
        # Airflow XComì— ì‹¤íŒ¨ ì •ë³´ ì €ìž¥
        context['ti'].xcom_push(key='crawl_status', value='failed')
        context['ti'].xcom_push(key='crawl_error', value=str(e))
        context['ti'].xcom_push(key='crawl_method', value='playwright')
        raise


def verify_mongodb_data(**context):
    """MongoDBì— ì €ìž¥ëœ ë°ì´í„° í™•ì¸ (Airflow ì „ìš© ëª¨ë“ˆ ì‚¬ìš©)"""
    import asyncio
    import logging
    from datetime import datetime, timedelta
    
    logger = logging.getLogger(__name__)
    logger.info("MongoDB ë°ì´í„° í™•ì¸ ì‹œìž‘...")
    
    # Airflow ì „ìš© ëª¨ë“ˆ ì‚¬ìš© (appê³¼ ì™„ì „ížˆ ë¶„ë¦¬)
    from airflow.scripts.mongodb_store import AirflowVectorStore
    
    ti = context['ti']
    
    async def _verify():
        vector_store = AirflowVectorStore()
        connected = await vector_store.connect()
        if not connected:
            logger.error("MongoDB ì—°ê²° ì‹¤íŒ¨")
            return None
        
        try:
            collection = vector_store.collection
            if collection is None:
                logger.error("MongoDB ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ìµœê·¼ 24ì‹œê°„ ë‚´ ì €ìž¥ëœ zendesk_article íƒ€ìž… ë¬¸ì„œ ìˆ˜
            yesterday = datetime.utcnow() - timedelta(days=1)
            
            count = await collection.count_documents({
                "metadata.type": "zendesk_article",
                "created_at": {"$gte": yesterday}
            })
            
            logger.info(f"âœ… ìµœê·¼ 24ì‹œê°„ ë‚´ ì €ìž¥ëœ FAQ ë¬¸ì„œ ìˆ˜: {count}ê°œ")
            
            # ì „ì²´ ë¬¸ì„œ ìˆ˜ í™•ì¸
            total_count = await collection.count_documents({
                "metadata.type": "zendesk_article"
            })
            logger.info(f"ðŸ“Š ì „ì²´ FAQ ë¬¸ì„œ ìˆ˜: {total_count}ê°œ")
            
            return {'count_24h': count, 'total': total_count}
            
        except Exception as e:
            logger.error(f"ë°ì´í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
        finally:
            await vector_store.disconnect()
    
    try:
        result = asyncio.run(_verify())
        if result:
            # XComì— í†µê³„ ì €ìž¥
            ti.xcom_push(key='documents_count_24h', value=result['count_24h'])
            ti.xcom_push(key='documents_count_total', value=result['total'])
            return True
        else:
            logger.warning("âš ï¸ ë°ì´í„° í™•ì¸ ì‹¤íŒ¨ (í¬ë¡¤ë§ì€ ì„±ê³µí–ˆì„ ìˆ˜ ìžˆìŒ)")
            return False
    except Exception as e:
        logger.error(f"ë°ì´í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


# ìž‘ì—… ì •ì˜
with TaskGroup("preparation", dag=dag) as prep_group:
    """ì¤€ë¹„ ìž‘ì—… ê·¸ë£¹"""
    check_playwright = PythonOperator(
        task_id='check_playwright_installation',
        python_callable=check_playwright_installation,
        dag=dag,
    )
    
    check_mongodb = PythonOperator(
        task_id='check_mongodb_connection',
        python_callable=check_mongodb_connection,
        dag=dag,
    )
    
    # Playwright í™•ì¸ í›„ MongoDB í™•ì¸
    check_playwright >> check_mongodb

with TaskGroup("crawling", dag=dag) as crawl_group:
    """í¬ë¡¤ë§ ìž‘ì—… ê·¸ë£¹"""
    crawl_task = PythonOperator(
        task_id='crawl_bithumb_faq',
        python_callable=run_crawl_bithumb_faq,
        dag=dag,
    )

with TaskGroup("verification", dag=dag) as verify_group:
    """ê²€ì¦ ìž‘ì—… ê·¸ë£¹"""
    verify_data = PythonOperator(
        task_id='verify_mongodb_data',
        python_callable=verify_mongodb_data,
        dag=dag,
    )

# ìž‘ì—… ì‹¤í–‰ ìˆœì„œ ì •ì˜
prep_group >> crawl_group >> verify_group
